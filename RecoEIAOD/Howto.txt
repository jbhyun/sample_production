<RecoEIAOD>

Modified from B2G-RunIIFall17DRPremix-02050

*setup commands
export VO_CMS_SW_DIR=/cvmfs/cms.cern.ch
source $VO_CMS_SW_DIR/cmsset_default.sh
export SCRAM_ARCH=slc6_amd64_gcc630
scram p CMSSW CMSSW_9_4_7
cd CMSSW_9_4_7/src/
cmsenv

git-cms-init
git clone https://github.com/jbhyun/sample_production
cd sample_production
git checkout -b Run2_17 origin/Run2_17
cd RecoEIAOD/<SNUNonbatch/CRAB>

1) SNUNonbatch
work on SNU nonbatch machines

 - Cleaner.sh : Remove miscellaneous log files created during the job running. Run it after all job done to clean space.
 - FileList.txt : Input file lists. write absolute paths. Only include file paths, with absence of empty lines.
 - RecoEIAOD_cfg.py : cfg file for RecoEIAOD production.
 - NonBatchSubmitter.sh : arrange running space, manage log files, submit jobs, manage output files if there is any finished jobs.
   - Params
     InputDir        : Unused variable for now
     OutDir          : If TrigMVOut=="T", then move cfg/log/output files to this absolute path
     OutFileNameBase : Output files will be named as ${OutFileNameBase}_1.root ...
     InFileList      : Location of input file list.
     Script          : Cfg file to run
     TrigDebug       : Debug mode ("T"/"F") - do not execute the cfg files, produce empty output files.
     TrigMVOut       : "T"/"F" - If TrigMVOut=="T", then move cfg/log/output files to $OutDir
     Nmax_phy        : number of allowed cores in the machine (physically maximal)
     Nmax_man        : set maximul number of simultaenous running jobs 
                       - The sample production takes very long time. For the courtesy of other potential users, you may wish to leave some cores free.
 - submit_cronjob_manual.sh : execute NonBatchSubmitter.sh at every designated time period until all job is finished.

  a) write input file list in FileList.txt
  b) set up the parameters in NonBatchSubmitter.sh
  c) set up the parameters in submit_cronjob_manual.sh and execute it (./submit_cronjob_manual.sh &)


2) CRAB_KNU
work on KNU machines using Crab, but can be easily modified to work on other machines by changing path settings

 - CrabInvalidator.sh : Invalidate publication of the output samples in the list.
                       - After finishing production you might not want to use earlier steps again, so delete the publication.
 - CrabSubmitter.sh : Script for managing crab jobs
   - Params
     ProdStep    : Name of the step. should be the same with the directory name before CRAB_SNU/ (e.g. "GENSIM"). 
                   This is used to label output/code/publication, etc.
     CrabCfgFile : Path to the CMSSW configuration file for crab submission. (e.g. "skeletons/crab_skeleton.py")
     ProdCfgFile : Path to the CMSSW configuration file for the production (e.g. "skeletons/GENSIM_LFilter_cfg.py")
     InputList   : Path to the text file of input file lists and their aliases. 
                   In the txt file, 1st/2nd column is for the aliases/paths with the delimiter ' '. Don't forget file:/root://cluster142.knu.ac.kr/ etc in the paths.
     ReSubList   : Path to the text file for resubmission. Same convension as $InputList.
     KillList    : Path to the text file for killing crab jobs. Same convention as $InputList.
     TrigDebug   : For debugging submission code ("T"/"F"). If "F", no crab submission executed, but log is written for planned commands.
     RunningMode : Which mode to be executed. Init - submit jobs for the first time / Resub - resubmission of jobs /Kill - kill the jobs / Pilot - pilot running (--dryrun option)
   
   - running path for crab submission will be Forge/${ProcName}, Logs will be in Logs/{CommandLogs.txt/StatusReport....txt ... }
 - skeletons : example config files are located. submission code fixes paths in these code and submit.

  a) Write the input lists & Minbias file list.
  b) Check/Edit the configuration in $CrabCfgFile/$ProdCfgFile
  c) Check the parameters in CrabSubmitter.sh
  d) (Optional) you may run a pilot run to check any weird config value in the files. If you want to use the functionality of memory/job splitting estimates, 
     change PilotOption="--dryrun --skip-estimates" to PilotOption="--dryrun" in the code.
  e) run the submission code (./CrabSubmitter.sh)
